version: 2.1

commands:
  setup_job:
    steps:
      - checkout
      - run:
          name: "Generate cache key"
          command: ./integration_tests/ci/checksum.sh

      - restore_cache:
          key: &deps1-cache deps1-{{ .Branch }}-{{ checksum "/tmp/checksum.txt" }}
      - run:
          name: "Setup profile"
          command: |
            mkdir -p ~/.dbt
            cp integration_tests/ci/profiles.yml ~/.dbt/profiles.yml
      - run:
          name: "Setup BigQuery Credentials"
          command: |
            echo $BIGQUERY_SERVICE_ACCOUNT_JSON > ${HOME}/bigquery-service-key.json
      - aws-cli/setup:
          role_arn: $AWS_ROLE_ARN

  setup_redshift:
    steps:
      # TODO: remove when https://github.com/dbt-labs/dbt-redshift/issues/729 is resolved
      - run:
          name: Add redshift URL to hosts
          command: |
            sudo tee -a /etc/hosts \<<<'127.0.0.1 ${REDSHIFT_URL}'
      - run:
          name: Setup SSH Tunnel
          command: |
            ssh-keygen -t rsa -f aws-temp -q -N "" \<<<y >/dev/null 2>&1

            aws ec2-instance-connect send-ssh-public-key \
              --region ${AWS_REGION_NAME} \
              --availability-zone ${AWS_AVAILABILITY_ZONE} \
              --instance-id ${BASTION_INSTANCE_ID}
              --instance-os-user ${AWS_BASTION_USER}
              --ssh-public-key file://aws-temp.pub

            ssh -N -f \
             -L 5439:${REDSHIFT_URL}:5439 \
              -o "IdentitiesOnly=yes" -o "Port=22" \
              -i aws-temp \
              ${AWS_BASTION_USER}@${BASTION_HOST}

orbs:
  aws-cli: circleci/aws-cli@4.1.3

jobs:
  setup_commit:
    docker:
      - image: cimg/python:3.11.4
    steps:
      - setup_job

      - run:
          name: "Setup dbt"
          command: |
            python3 -m venv venv
            . venv/bin/activate

            pip install --upgrade pip
            pip install -r requirements.txt

            cd integration_tests
            dbt deps
      - save_cache:
          key: *deps1-cache
          paths:
            - "venv"
            - "integration_tests/dbt_packages"

  compile:
    docker:
      - image: cimg/python:3.11.4

    steps:
      - setup_job
      - run:
          name: "Compile - BigQuery"
          environment:
            BIGQUERY_SERVICE_KEY_PATH: "/home/circleci/bigquery-service-key.json"
          command: |
            . venv/bin/activate
            echo `pwd`
            cd integration_tests
            dbt compile --target bigquery

      - run:
          name: "Compile - Snowflake"
          command: |
            . venv/bin/activate
            echo `pwd`
            cd integration_tests
            dbt compile --target snowflake

      - run:
          name: "Compile - Redshift"
          command: |
            . venv/bin/activate
            echo `pwd`
            cd integration_tests
            dbt compile --target redshift

  bigquery_test:
    docker:
      - image: cimg/python:3.11.4
    steps:
      - setup_job

      - run:
          name: "Test - BigQuery"
          environment:
            BIGQUERY_SERVICE_KEY_PATH: "/home/circleci/bigquery-service-key.json"
          command: |
            . venv/bin/activate
            echo `pwd`
            cd integration_tests
            dbt seed --target bigquery --full-refresh
            dbt compile --target bigquery
            dbt run --target bigquery --full-refresh --select bigquery_events_shim
            dbt run --target bigquery --full-refresh
            dbt test --target bigquery

  bigquery_v2_test:
    docker:
      - image: cimg/python:3.11.4
    steps:
      - setup_job

      - run:
          name: "Test - BigQuery V2"
          environment:
            BIGQUERY_SERVICE_KEY_PATH: "/home/circleci/bigquery-service-key.json"
          command: |
            . venv/bin/activate
            echo `pwd`
            cd integration_tests
            dbt seed --target bigquery_v2 --full-refresh
            dbt compile --target bigquery_v2 --vars '{"fullstory_skip_json_parse": true}'
            dbt run --target bigquery_v2 --full-refresh --select bigquery_v2_events_shim --vars '{"fullstory_skip_json_parse": true}'
            dbt run --target bigquery_v2 --full-refresh --vars '{"fullstory_skip_json_parse": true}'
            dbt test --target bigquery_v2 --vars '{"fullstory_skip_json_parse": true}'

  snowflake_test:
    docker:
      - image: cimg/python:3.11.4
    steps:
      - setup_job

      - run:
          name: "Test - Snowflake"
          command: |
            . venv/bin/activate
            echo `pwd`
            cd integration_tests
            dbt seed --target snowflake --full-refresh
            dbt compile --target snowflake
            dbt run --target snowflake --full-refresh --select snowflake_events_shim
            dbt run --target snowflake --full-refresh
            dbt test --target snowflake

  redshift_test:
    docker:
      - image: cimg/python:3.11.4
    steps:
      - setup_job
      - setup_redshift
      - run:
          name: "Test - Redshift"
          command: |
            . venv/bin/activate
            echo `pwd`
            cd integration_tests
            dbt seed --target redshift --full-refresh
            dbt compile --target redshift
            dbt run --target redshift --full-refresh --select redshift_events_shim
            dbt run --target redshift --full-refresh
            dbt test --target redshift

workflows:
  commit:
    jobs:
      - setup_commit
      - compile:
          requires:
            - setup_commit
      - wait_for_approval:
          type: approval
          requires:
            - compile
      - bigquery_test:
          requires:
            - wait_for_approval
      - snowflake_test:
          requires:
            - wait_for_approval
      - redshift_test:
          requires:
            - wait_for_approval
